[
  {
    "objectID": "program/index.html",
    "href": "program/index.html",
    "title": "Programa",
    "section": "",
    "text": "Hora\nLunes 11 de noviembre\nMartes 12 de noviembre\n\n\n\n\n09:35 - 09:50\nBienvenida-Inauguración\n\n\n\n09:50 - 10:30\nSoledad Torres Díaz  (Universidad Central)\nFelipe Barrientos  (Florida State University, EEUU)\n\n\n10:30 - 11:10\nHéctor Araya Carvajal  (Universidad Adolfo Ibáñez)\nClaudia Chavez  (Investigadora FLACSO)\n\n\n11:10 - 11:30\nCoffee Break\nCoffee Break\n\n\n11:30 - 12:00\nMini curso Quarto - Github  Francisco Plaza-Vega\nMini curso Quarto - Github  Francisco Plaza-Vega\n\n\n12:00 - 13:20\nSesiones Orales\nSesiones Orales\n\n\n\nPartial identification in ILSA studies of educational achievement: A strategy for producing credible interval estimates with student non-participation  Maximiliano Romero (Afiliación pendiente)\nPredicción de Desembarcos de Pulpo (Octopus vulgaris) con Inteligencia Artificial: Una Demo Interactiva en R  Victor Sanz-Fernández (PUCV)\n\n\n\nFactores asociados en el rendimiento de pruebas Simce: propuesta de análisis inferencial y hallazgos  Esteban Avarca Oviedo (USACH)\nAnálisis de factores de reincidencia delictual en Chile utilizando Machine Learning y Técnicas de Agrupamiento  Vicente Jopia Alburquenque (USACH)\n\n\n\nModelo BNP para datos discretos con aplicación al rendimiento de clubes deportivos  Cristian Capetillo Constela (PUC)\nEl uso de los modelos de distribución de especies para la construcción de distribuciones a priori en inferencia bayesiana  Mateo Antonio Morales Herrera (UChile)\n\n\n\nWeibull random fields through Clayton spatial copula: an application to mining haul roads  Eloy Alvarado Narváez (UTFSM)\nEstimación de Parámetros mediante Simulación-Extrapolación en Procesos Autorregresivos cercanos a la Raíz Unitaria  Pablo Vicari Ruiz (USACH)\n\n\n13:20 - 14:00\nCoffee Break - Posters\nCoffee Break - Posters\n\n\n\n\n\n\n Volver arriba"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "III Jornadas Ingeniería Estadística",
    "section": "",
    "text": "Hemos actualizado el programa para incorporar más presentaciones, dada la alta convocatoria que hemos recibido. ¡Gracias por el entusiasmo!\n\n\nLa participación en las Jornadas puede ser como:\n- Presentador: Formato oral (presentación corta) o póster.\n- Asistente: ¡Cupos limitados! Los invitamos a inscribirse pronto para asegurar su participación.\nPronto pondremos a disposición un formulario de inscripción adicional para los asistentes. ¡No te quedes fuera!\n\n\n\n\n\nLos interesados en presentar pueden enviar sus trabajos para ser considerados en formato oral o póster en las 3ras Jornadas de Ingeniería Estadística de la USACH.\n\n\n\n\nFecha Límite de envío de resúmenes: 14 de Octubre\n\n\n\n\nFormulario de inscripción de trabajos\n\n\n\n\n\n¡Consulta el programa completo! No te pierdas ninguna de las actividades y asegúrate de inscribirte a tiempo para participar."
  },
  {
    "objectID": "index.html#atención",
    "href": "index.html#atención",
    "title": "III Jornadas Ingeniería Estadística",
    "section": "",
    "text": "Extendimos el plazo para presentación de resúmenes para el 14 de Octubre de 2024!."
  },
  {
    "objectID": "index.html#extensión-del-envío-de-resúmenes",
    "href": "index.html#extensión-del-envío-de-resúmenes",
    "title": "III Jornadas Ingeniería Estadística",
    "section": "",
    "text": "Extendimos el plazo para presentación de resúmenes para el 14 de Octubre de 2024!.\n\n\nLos participantes interesados pueden postular sus trabajos, para ser presentados en formato oral (presentación corta) y/o póster en las 3ras Jornadas de Ingeniería Estadística de la USACH.\n\n\n\n\nFecha Límite de envío de resúmenes: 14 de Octubre\n\n\n\n\nFormulario de inscripción de trabajos"
  },
  {
    "objectID": "index.html#extensión-del-envío-de-resúmenes-14-de-octubre-2024",
    "href": "index.html#extensión-del-envío-de-resúmenes-14-de-octubre-2024",
    "title": "III Jornadas Ingeniería Estadística",
    "section": "",
    "text": "Los participantes interesados pueden postular sus trabajos, para ser presentados en formato oral (presentación corta) y/o póster en las 3ras Jornadas de Ingeniería Estadística de la USACH.\n\n\n\n\nFecha Límite de envío de resúmenes: 14 de Octubre\n\n\n\n\nFormulario de inscripción de trabajos"
  },
  {
    "objectID": "index.html#cómo-llegar",
    "href": "index.html#cómo-llegar",
    "title": "III Jornadas Ingeniería Estadística",
    "section": "Cómo llegar",
    "text": "Cómo llegar\nPuedes encontrar la ubicación del Departamento de Matemática y Ciencia de la Computación (DMCC) en la Universidad de Santiago de Chile (USACH) en el siguiente mapa:"
  },
  {
    "objectID": "index.html#programa-actualizado",
    "href": "index.html#programa-actualizado",
    "title": "III Jornadas Ingeniería Estadística",
    "section": "",
    "text": "Hemos actualizado el programa para incorporar más presentaciones, dada la alta convocatoria que hemos recibido. ¡Gracias por el entusiasmo!\n\n\nLa participación en las Jornadas puede ser como:\n- Presentador: Formato oral (presentación corta) o póster.\n- Asistente: ¡Cupos limitados! Los invitamos a inscribirse pronto para asegurar su participación.\nPronto pondremos a disposición un formulario de inscripción adicional para los asistentes. ¡No te quedes fuera!\n\n\n\n\n\nLos interesados en presentar pueden enviar sus trabajos para ser considerados en formato oral o póster en las 3ras Jornadas de Ingeniería Estadística de la USACH.\n\n\n\n\nFecha Límite de envío de resúmenes: 14 de Octubre\n\n\n\n\nFormulario de inscripción de trabajos\n\n\n\n\n\n¡Consulta el programa completo! No te pierdas ninguna de las actividades y asegúrate de inscribirte a tiempo para participar."
  },
  {
    "objectID": "abstracts/index.html",
    "href": "abstracts/index.html",
    "title": "Resúmenes",
    "section": "",
    "text": "Partial identification in ILSA studies of educational achievement: A strategy for producing credible interval estimates with student non-participation\nMaximiliano Romero\n(Afiliación pendiente)\nEste trabajo aborda el problema de la no participación estudiantil en los estudios internacionales de evaluación a gran escala (ILSA), que afecta la estimación de parámetros poblacionales como el rendimiento promedio. Tradicionalmente, estos estudios suponen que la no participación es ignorada, lo que permite obtener estimaciones puntuales de los parámetros. Sin embargo, este enfoque depende de una fuerte suposición de independencia entre el rendimiento de los estudiantes y su probabilidad de participar, lo que puede no ser realista y comprometer la credibilidad de los resultados.\nEl enfoque propuesto introduce la identificación parcial para producir estimaciones intervalares más creíbles bajo supuestos menos restrictivos. La identificación parcial permite generar intervalos que reflejan tanto el error muestral como la incertidumbre estructural provocada por la falta de datos de los estudiantes no participantes. Esto se logra sin imponer suposiciones fuertes sobre el rendimiento de los no participantes, evitando la necesidad de depender únicamente de los datos observados.\nUtilizando datos del International Computer and Information Literacy Study (ICILS 2018), se ilustran diferentes escenarios que muestran cómo varían los intervalos de estimación del rendimiento promedio según los supuestos sobre la no participación. El enfoque permite ajustar la amplitud de los intervalos según el grado de credibilidad de las suposiciones impuestas, mejorando la robustez de los resultados en comparación con los enfoques tradicionales que eliminan la ambigüedad, pero a costa de la credibilidad.\nEl artículo ofrece una metodología para manejar la incertidumbre no muestral y propone la combinación de técnicas de muestreo con análisis de identificación parcial para obtener intervalos creíbles. Este enfoque proporciona una herramienta valiosa en el análisis de estudios como PISA y TIMSS, donde la no participación es un problema recurrente y puede introducir sesgos significativos en la estimación de parámetros clave.\nLa identificación parcial permite explorar una serie de suposiciones intermedias entre los extremos de ignorabilidad total y mínimas restricciones, contribuyendo a una estimación más robusta y creíble de los parámetros poblacionales. Este trabajo destaca cómo el uso de intervalos de identificación parcial puede mejorar la interpretación de los resultados en estudios con tasas de participación subóptimas.\n\n\n\nFactores asociados en el rendimiento de pruebas Simce: propuesta de análisis inferencial y hallazgos\nEsteban Avarca Oviedo\nUniversidad de Santiago de Chile\nLa Agencia de Calidad de la Educación desarrolló una herramienta con el propósito de estudiar y analizar cómo distintos aspectos de la experiencia escolar se asocian con los resultados educativos de la prueba Simce y de los Indicadores de desarrollo personal y social (IDPS). Estos son los denominados “factores asociados” que refieren sobre variadas temáticas educativas y son evaluados por medio de los Cuestionarios de Calidad Simce.\nEl desarrollo de estos factores se realiza en etapas, primero recopilando la información mediante la aplicación del Simce, que incluye tanto las pruebas de conocimiento como los resultados de los Cuestionarios de Calidad y Contexto de la Educación (CCCE) y a través de la información proporcionada por el Ministerio de Educación.\nEn una segunda etapa, se definen las variables dependientes (puntajes SIMCE y resultados IDPS) e independientes. La construcción de los factores asociados como variables independientes desempeña un papel crucial en esta metodología y sigue un proceso específico. En primer lugar, se definen teóricamente las variables que se espera que estén asociadas con Simce y que permitan ofrecer recomendaciones respecto a la gestión educativa. Posteriormente, este constructo se elabora mediante un conjunto de ítems de los CCCE, y su cuantificación se realiza mediante un análisis factorial. Además, es importante destacar que los factores asociados medidos son para distintos actores que completaron los Cuestionarios, tales como estudiantes, padres o apoderados, docentes y directores.\nLa tercera etapa contempla la estrategia de análisis, para ello se realiza un Modelamiento estadístico utilizando las variables explicadas y explicativas. El modelo utilizado corresponde a un modelo lineal jerárquico que permite distinguir la variabilidad entre los distintos niveles de análisis, en este caso estudiantes y establecimientos educativos. La selección de las variables que se incluyen en cada modelo es determinada desde una revisión teórica. Es decir, se seleccionan las variables que se espera desde la teoría tengan una asociación con Simce e IDPS. Luego, algunas de estas variables se pueden descartar por varios aspectos, el primero de ellos es por multicolinealidad, otro aspecto a considerar para descartar variables corresponde a la significancia y signo esperado, donde posterior al modelamiento se verifica qué variables son significativas en el modelo y tengan un signo esperado teóricamente. Luego, para las variables que resultan del modelo final se obtiene una magnitud de la asociación. Esta magnitud es obtenida con la siguiente metodología: (1) Para cada factor asociado se generan cuatro grupos, definidos por los cuartiles de la variable, (2) Se obtiene para cada grupo el valor esperado promedio del grupo utilizando las estimaciones del modelo y (3) Se realiza la diferencia del grupo con mejores y peores resultados en términos del Simce esperado, obteniendo así la magnitud de la estimación. Esta magnitud se utiliza como una referencia de las diferencias que se pueden generar en Simce al tener mejores resultados en un Factor Asociado.\nUtilizando la metodología antes descrita, se estimó que factores como “Ambiente protegido”, “Mentalidad de crecimiento” y “Expectativas de padres y madres” tienen un “impacto” relevante en los resultados académicos.\n\n\n\nModelo BNP para datos discretos con aplicación al rendimiento de clubes deportivos\nCristian Capetillo Constela\nPontificia Universidad Católica de Chile\nEn toda área del conocimiento existe un interés particular en los datos del tipo discreto. Se podrían mencionar fácilmente datos como la frecuencia de eventos sísmicos, el número de productos vendidos por una tienda, el número de cigarrillos fumados por persona y el número de automóviles en una intersección, cada uno relacionado con la geología, la economía, la medicina o la planificación urbana, respectivamente.\nEn el contexto de los modelos paramétricos, el primer modelo para datos discretos, en particular de conteo, es el popular modelo de Poisson. Tal popularidad, lamentablemente, viene acompañada de su característica restrictiva de equidispersión. Alternativas al modelo de Poisson son la distribución Binomial-Negativa o versiones cero-infladas tales como los modelos ZIP y ZINB (véase, por ejemplo, Agresti, 2002). Sin embargo, la naturaleza restrictiva de los modelos paramétricos es bien conocida. Con un espacio de parámetros de dimensión finita, se podría caer en un problema de especificación. Más aún, un modelo paramétrico puede verse como caso particular de uno no paramétrico (Ghosal y van der Vaart, 2017).\nLa teoría Bayesiana No Paramétrica (BNP) está bien desarrollada en el contexto de variables aleatorias continuas. Para datos discretos, la afirmación puede ser al menos discutible. La incorporación de una variable subyacente continua, sin embargo, puede ayudar a transferir la teoría continua a una discreta. En este trabajo se desarrolla un modelo de regresión flexible y una metodología de selección de modelos para datos de tipo discreto utilizando el redondeo de kernels continuos (ver Canale y Dunson (2011)). En particular, se desarrolla un modelo LDDP redondeado, dotado de un esquema MCMC para un fácil cálculo a posteriori. El modelo se somete a un estudio de simulación y se aplica a un conjunto de datos correspondiente al desempeño de un equipo de fútbol a través de los años.\nNota: Las simulaciones iniciales no han sido exhaustivas. No obstante, los resultados preliminares sugieren un buen comportamiento asintótico del modelo, abriendo un camino prometedor para su desarrollo.\n\n\n\nWeibull random fields through Clayton spatial copula: an application to mining haul roads\nEloy Alvarado Narváez\nUniversidad Técnica Federico Santa María\nThe precise assessment and characterization of road surfaces are crucial for maintaining operational efficiency and ensuring the reliability of transportation networks. This is especially true for off-the-road surfaces in mining operations, where irregular terrains pose unique challenges that traditional evaluation methods often fail to capture. As a result, there is a need for more sophisticated approaches that can better model the complexity of these environments.\nIn response to this challenge, we propose the construction of a Weibull random field using a spatial Clayton copula framework. This approach allows for greater flexibility by accommodating different types of asymmetries, making it particularly well-suited for the irregular patterns observed in mining haul roads. We investigate the second-order and geometrical properties of the proposed Weibull process and derive analytical expressions for the bivariate distribution.\nTo further assess our model, we compare it with two alternative approaches: a Weibull random field obtained via a monotone transformation of a scaled χ² random process, and a model based on the classical Gaussian copula. The effectiveness of our methodology is demonstrated through the analysis of high-resolution imagery from Mina Sur in northern Chile, showing that the proposed model provides a more accurate representation of the spatial structure of haul road surfaces than traditional methods.\n\n\n\nPredicción de Desembarcos de Pulpo (Octopus vulgaris) con Inteligencia Artificial: Una Demo Interactiva en R\nVictor Sanz-Fernández\nPontificia Universidad Católica de Valparaíso\nLa pesquería de pulpo (Octopus vulgaris) tiene una gran relevancia económica y social en el golfo de Cádiz, en el sur de España, y representa una actividad clave tanto para la economía local como para la Unión Europea. Poder prever los desembarques de esta especie es esencial para gestionar la pesquería de manera sostenible y tomar decisiones fundamentadas sobre su explotación. En este estudio, se emplean modelos de inteligencia artificial, específicamente redes neuronales autorregresivas, para capturar los patrones complejos y no lineales que caracterizan los desembarques de pulpo. Los datos de desembarques comerciales (primera venta) utilizados provienen del Sistema de Información Andaluz de Comercialización y Producción Pesquera (IDAPES) de Andalucía (España) y cubren el periodo desde enero de 2000 hasta diciembre de 2022 para las regiones suratlántica y mediterránea de Andalucía. Dado que los juveniles de esta especie se asientan entre septiembre y noviembre después del reclutamiento y el desove ocurre en verano en ambas regiones, los desembarques de octubre de un año hasta septiembre del año siguiente se consideran una cohorte. Así, el registro temporal comprende desde octubre de 2000 hasta septiembre de 2022.\nDurante la presentación en las III Jornadas de Ingeniería Estadística de la Universidad de Santiago de Chile (USACH), se realizará una demostración en vivo en R donde se aplicarán modelos de redes neuronales autorregresivas para proyectar los desembarques de pulpo en dos escenarios para ambas regiones: uno a corto plazo, correspondiente a 2023, y otro a largo plazo, que abarca el periodo 2023-2024. Para construir y calibrar estos modelos, se utilizó el 95% de los datos históricos (2000-2021), mientras que el 5% restante (2022) se reservó para una validación externa. En esta fase de construcción y calibración, se probaron seis configuraciones del parámetro de decaimiento del peso (decay: 0, 0.1, 0.2, 0.3, 0.4 y 0.5), seleccionando la mejor opción según el índice de persistencia (PI). La validación externa de los modelos se evaluó con diversos criterios de error: coeficiente de determinación (\\(R^2\\)), raíz cuadrada del error cuadrático medio (RMSE), error absoluto medio (MAE), coeficiente de eficiencia (\\(E_2\\)) y el índice de persistencia con desfase de un mes.\n\n\n\nAnálisis de factores de reincidencia delictual en Chile utilizando Machine Learning y Técnicas de Agrupamiento\nVicente Jopia Alburquenque\nUniversidad de Santiago de Chile\nEn este trabajo, inscrito en el proyecto Fondecyt 1210254, se busca identificar las características que inciden en la reincidencia delictual en condenados de cárceles chilenas en cinco regiones. Utilizando técnicas de machine learning, se ha trabajado con una base de datos proporcionada por Gendarmería de Chile, la cual abarca información de variables demográficas de condenados desde el año 2015 hasta 2020. Se realizó un análisis exploratorio de datos, abordando problemas de registro, datos faltantes y la conversión de la fecha de nacimiento en la edad al momento del primer egreso para cada persona.\nComo variables relevantes es necesario destacar la edad, comuna, delitos cometidos, nacionalidad, reincidencia y sexo de los individuos, las cuales fueron transformadas en variables dummy donde en el caso de la reincidencia toma el valor uno si es que el individuo posee dos o más condenas y el valor cero en caso contrario. Para los delitos se creó un DataFrame donde cada columna representa cada tipo de delito y cada fila corresponde a una persona, registrando la frecuencia con que cometió cada delito: un valor de 0 si no lo cometió, 1 si lo cometió una vez, y 2 o más si lo cometió en múltiples ocasiones.\nPosteriormente, las variables se agruparon en dos conjuntos para analizar su variabilidad a través de técnicas de clustering basadas en densidad. Observando los resultados del clustering mediante t-sne, estos mostraron una alta variabilidad en las variables demográficas edad, sexo, nacionalidad y comuna, mientras que las variables relacionadas con los delitos no presentaron la misma dispersión. Debido a esta observación, se decidió enfocar el análisis en los delitos para estimar la reincidencia.\nAl realizar el análisis de clustering, como las variables a trabajar son discretas, se decidió ocupar el modelo de agrupamiento Density-based spatial clustering of applications with noise (DBSCAN), la métrica de distancia utilizada fue la distancia Jaccard y también se implementó la métrica average silhouette, Calinski-Harabasz y Davies-Bouldin, con el fin de determinar el número óptimo de clusters a trabajar.\nDado a los requerimientos computacionales y el tamaño de la base de datos (más de 200,000 observaciones), se trabajó con un máximo del veinte por ciento de los datos para el análisis de clustering, y después de definir el número de clusters a trabajar, estos se caracterizaron identificando por cuántos delitos estaban compuestos cada uno y luego se utilizó un modelo de árbol de decisión para predecir a qué cluster pertenecen los datos que aún no han sido analizados de la base de datos utilizando la métrica F1 para medir el rendimiento predictivo del modelo.\n\n\n\nEl uso de los modelos de distribución de especies para la construcción de distribuciones a priori en inferencia bayesiana\nMateo Antonio Morales Herrera\nUniversidad de Chile\nEste trabajo se sitúa en la intersección del modelamiento de nicho climático y la inferencia bayesiana, combinando dos enfoques importantes en ecología. El modelamiento de nicho climático se basa en el concepto de Hutchinson, que permite identificar áreas ambientales favorables o desfavorables de una especie, mientras que la inferencia bayesiana se utiliza para incorporar información externa en la prueba de hipótesis.\nEl objetivo principal es utilizar el modelamiento de nicho climático para generar distribuciones a priori informativas que comparen la proporción de sitios ocupados por especies exóticas en diferentes ambientes dentro de un procedimiento bayesiano (factor de Bayes). Para esto, se trabajará con cuatro especies de leguminosas exóticas en Chile Central. La investigación propone construir el nicho climático para realizar un muestreo aleatorio de espacios adecuados (1) y no adecuados (0) para las especies, obteniendo distribuciones a priori que permitan realizar una prueba de hipótesis.\nEn lugar de utilizar información a priori no informativa, común en estudios ecológicos, se usará información derivada del modelamiento de nicho. Estos datos binarios permitirán estimar distribuciones Beta, que son adecuadas para representar la proporción de sitios ocupados por las especies. Finalmente, la comparación entre ambientes se hará utilizando tanto información de campo como los modelos de nicho, empleando el factor de Bayes como estadístico de prueba.\n\n\n\nEstimación de Parámetros mediante Simulación-Extrapolación en Procesos Autorregresivos cercanos a la Raíz Unitaria\nPablo Vicari Ruiz\nUniversidad de Santiago de Chile\nEn la actualidad, el análisis de series temporales ha adquirido una gran relevancia debido a su capacidad para modelar y predecir fenómenos en áreas tan diversas como la economía, la climatología y la epidemiología. En este contexto, los modelos autorregresivos (AR) juegan un papel crucial al permitir estimar la evolución futura de una variable a partir de sus valores pasados. El presente trabajo se enfoca en mejorar la precisión en la estimación del parámetro \\(\\phi\\) en procesos autorregresivos, con especial énfasis en escenarios cercanos a la raíz unitaria. Estos escenarios son fundamentales para entender la dependencia temporal en los modelos AR y los modelos autorregresivos irregulares (iAR), que son esenciales para capturar la dinámica de los datos en diversos campos del conocimiento.\nPara abordar esta problemática, se implementó el algoritmo SIMEX (Simulación-Extrapolación), originalmente desarrollado en el contexto de regresión, pero cuya aplicación a modelos autorregresivos es un campo en exploración. En este trabajo, se aplicó SIMEX con el objetivo de corregir el sesgo causado por la cercanía a la raíz unitaria en la estimación del parámetro \\(\\phi\\). Se probaron múltiples combinaciones de parámetros con el fin de identificar la configuración óptima para dicha estimación. Además, el rendimiento de SIMEX fue comparado con los enfoques tradicionales de estimación, como Máxima Verosimilitud (MLE) y Mínimos Cuadrados Ordinarios (LSE).\n\n\n\n\n Volver arriba"
  }
]